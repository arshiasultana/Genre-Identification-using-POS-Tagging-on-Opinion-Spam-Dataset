{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_spam=pd.read_csv(\"deceptive-opinion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=opinion_spam.loc[opinion_spam['polarity']==\"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['deceptive'] = df['deceptive'].map({'truthful': 1, 'deceptive': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_process function for making tokens of data\n",
    "def text_process(mess):\n",
    "    return mess.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10224\n"
     ]
    }
   ],
   "source": [
    "#creating a bow transformer with token analyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(df['text'])\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bow_transformer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(bow_transformer.vocabulary_))\n",
    "#print(bow_transformer)\n",
    "#message_bow.shape\n",
    "#non nulls\n",
    "#message_bow.nnz\n",
    "#message_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the text in df to vectors after tokenization using count vectorizer\n",
    "message_bow=bow_transformer.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "text_train,text_test,label_train,label_test= train_test_split(df['text'],df['deceptive'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report without POS Tagging for 800 reviews using SVM Classifier\n",
      " \n",
      "svm               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.16      0.27       122\n",
      "           1       0.53      0.97      0.68       118\n",
      "\n",
      "    accuracy                           0.56       240\n",
      "   macro avg       0.68      0.57      0.48       240\n",
      "weighted avg       0.68      0.56      0.47       240\n",
      "\n",
      "5 Fold Cross Validation Score: [0.7     0.6125  0.68125 0.66875 0.54375]\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "Classification report without POS Tagging for 800 reviews using MultinomialNB Classifier\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       122\n",
      "           1       0.93      0.81      0.86       118\n",
      "\n",
      "    accuracy                           0.88       240\n",
      "   macro avg       0.88      0.87      0.87       240\n",
      "weighted avg       0.88      0.88      0.87       240\n",
      "\n",
      "5 Fold Cross Validation Score: [0.89375 0.86875 0.9     0.875   0.89375]\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "Classification report without POS Tagging for 800 reviews using Logistic Regression Classifier\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       122\n",
      "           1       0.88      0.86      0.87       118\n",
      "\n",
      "    accuracy                           0.88       240\n",
      "   macro avg       0.88      0.87      0.87       240\n",
      "weighted avg       0.88      0.88      0.87       240\n",
      "\n",
      "5 Fold Cross Validation Score: [0.84375 0.8375  0.8875  0.85    0.8875 ]\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "Classification report without POS Tagging for 800 reviews using Decision Tree Classifier\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71       122\n",
      "           1       0.70      0.63      0.66       118\n",
      "\n",
      "    accuracy                           0.69       240\n",
      "   macro avg       0.69      0.69      0.69       240\n",
      "weighted avg       0.69      0.69      0.69       240\n",
      "\n",
      "5 Fold Cross Validation Score: [0.625   0.675   0.63125 0.675   0.675  ]\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "Classification report without POS Tagging for 800 reviews using Random Forest Classifier\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73       122\n",
      "           1       0.74      0.57      0.64       118\n",
      "\n",
      "    accuracy                           0.69       240\n",
      "   macro avg       0.70      0.69      0.69       240\n",
      "weighted avg       0.70      0.69      0.69       240\n",
      "\n",
      "5 Fold Cross Validation Score: [0.7     0.71875 0.75625 0.71875 0.75   ]\n",
      "\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#data pipeline is used to store pipeline of workflow\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier ,export_text\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#creating a pipeline for svm and doing predictions\n",
    "pipeline_svm=Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('classifier',SVC())\n",
    "])\n",
    "pipeline_svm.fit(text_train,label_train)\n",
    "predictions_svm=pipeline_svm.predict(text_test)\n",
    "score_svm=cross_val_score(SVC(),message_bow,df['deceptive'],cv=5)\n",
    "\n",
    "print(\"Classification report without POS Tagging for 800 reviews using SVM Classifier\")\n",
    "print(\" \")\n",
    "print(\"svm\",classification_report(label_test,predictions_svm))\n",
    "print(\"5 Fold Cross Validation Score:\",score_svm)\n",
    "print(\"\")\n",
    "\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "#creating a pipeline for text processing and fitting our data in the pipeline NB\n",
    "pipeline=Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('classifier',MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline.fit(text_train,label_train)\n",
    "\n",
    "#prediction\n",
    "predictions=pipeline.predict(text_test)\n",
    "score_NB=cross_val_score(MultinomialNB(),message_bow,df['deceptive'],cv=5)\n",
    "print(\"Classification report without POS Tagging for 800 reviews using MultinomialNB Classifier\")\n",
    "print(\" \")\n",
    "print(classification_report(label_test,predictions))\n",
    "print(\"5 Fold Cross Validation Score:\",score_NB)\n",
    "print(\"\")\n",
    "\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "\n",
    "#creating a pipeline for Logistic Regression and doing predictions\n",
    "pipeline_LR=Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('classifier',LogisticRegression(max_iter=200))\n",
    "])\n",
    "pipeline_LR.fit(text_train,label_train)\n",
    "predictions_LR=pipeline_LR.predict(text_test)\n",
    "score_LR=cross_val_score(LogisticRegression(max_iter=200),message_bow,df['deceptive'],cv=5)\n",
    "print(\"Classification report without POS Tagging for 800 reviews using Logistic Regression Classifier\")\n",
    "print(\" \")\n",
    "print(classification_report(label_test,predictions_LR))\n",
    "print(\"5 Fold Cross Validation Score:\",score_LR)\n",
    "print(\"\")\n",
    "\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "\n",
    "#creating a pipeline for DecisionTreeClassifier and doing predictions\n",
    "pipeline_DT=Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('classifier',DecisionTreeClassifier())\n",
    "])\n",
    "pipeline_DT.fit(text_train,label_train)\n",
    "predictions_DT=pipeline_DT.predict(text_test)\n",
    "score_DT=cross_val_score(DecisionTreeClassifier(),message_bow,df['deceptive'],cv=5)\n",
    "print(\"Classification report without POS Tagging for 800 reviews using Decision Tree Classifier\")\n",
    "print(\" \")\n",
    "print(classification_report(label_test,predictions_DT))\n",
    "print(\"5 Fold Cross Validation Score:\",score_DT)\n",
    "print(\"\")\n",
    "\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "\n",
    "#creating a pipeline for RandomForestClassifier and doing predictions\n",
    "pipeline_RF=Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('classifier',RandomForestClassifier())\n",
    "])\n",
    "pipeline_RF.fit(text_train,label_train)\n",
    "predictions_RF=pipeline_RF.predict(text_test)\n",
    "score_RF=cross_val_score(RandomForestClassifier(),message_bow,df['deceptive'],cv=5)\n",
    "print(\"Classification report without POS Tagging for 800 reviews using Random Forest Classifier\")\n",
    "print(\" \")\n",
    "print(classification_report(label_test,predictions_RF))\n",
    "print(\"5 Fold Cross Validation Score:\",score_RF)\n",
    "print(\"\")\n",
    "\n",
    "print(\"------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
